# -*- coding: utf-8 -*-
"""Copy of mobile_classification new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uiQ3dHBS4czaWXMLRXpUev3R9rmPM5m_
"""

# Commented out IPython magic to ensure Python compatibility.
#Import libraries
import pandas as pd
import numpy as np

#visualisation
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly
import plotly.offline as pyo
from plotly.offline import iplot
import plotly.express as px
from plotly.subplots import make_subplots

# data splitting
from sklearn.model_selection import train_test_split

# data modeling
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC

# Model performance
from sklearn.model_selection import RandomizedSearchCV,GridSearchCV
from sklearn.model_selection import  KFold, cross_val_score, StratifiedKFold
from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report, roc_curve , precision_score,recall_score
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import label_binarize
from sklearn.preprocessing import StandardScaler, MinMaxScaler

#warnings
import warnings
warnings.simplefilter(action='ignore')

import seaborn as sns
from sklearn.pipeline import Pipeline

#read_data
train_data=pd.read_csv("/content/train.csv")

#dataframe
df_train=pd.DataFrame(train_data)
df_train

df_train.info()

df_train.nunique()

df_train.price_range.nunique()

duplicates = df_train.duplicated().sum()
print("\nNumber of Duplicate Rows:", duplicates)
df_train = df_train.drop_duplicates()

duplicates_col = df_train.columns.duplicated().sum()
print("Number of Duplicate Columns:", duplicates_col)
data = df_train.loc[:, ~df_train.columns.duplicated()]

missing_values = df_train.isnull().sum()
print("\nMissing Values:\n", missing_values)

X = df_train.drop('price_range', axis=1)  # Replace 'target_column' with your actual target column name
y = df_train['price_range']

print("unique values in y:",y.unique())

y=y.astype('int')

if y.duplicated().any():
  print("Duplicated values found in y.")
  y = y.drop_duplicates()
else:
    print("No duplicated values found in y.")

y = y.drop_duplicates()

# Count the class distribution
print("Class distribution:\n", pd.Series(y).value_counts())

import matplotlib.pyplot as plt

# Plot histogram
plt.hist(y, bins=20, edgecolor='k')
plt.title("Distribution of y (price_range)")
plt.xlabel("Price Range")
plt.ylabel("Frequency")
plt.show()

# Separate features (X) and target variable (y)
X = df_train.drop('price_range', axis=1)  # Replace 'target_column' with your actual target column name
y = df_train['price_range']

corr=df_train.corr()
fig = plt.figure(figsize=(15,12))
r = sns.heatmap(corr, cmap='Purples')
r.set_title("Correlation ")

#price range correlation
corr.sort_values(by=["price_range"],ascending=False).iloc[0].sort_values(ascending=False)

#price range and ram 0.917 corelation

import xgboost as xgb

# Assuming you have your training data X and y
model = xgb.XGBClassifier()  # or xgb.XGBRegressor()
model.fit(X, y)

# Now you can access feature importances
feat_imp = pd.Series(model.feature_importances_, index=X.columns)
feat_imp.nlargest(10).plot(kind='barh')

# plot the graph of feature importances for better visualization

feat_imp = pd.Series(model.feature_importances_, index=X.columns)
feat_imp.nlargest(10).plot(kind='barh')

plt.figure(figsize=(8,6))
plt.show()

sns.countplot(df_train['price_range'])
plt.show()

def missing_check(df_train):
    total = df_train.isnull().sum().sort_values(ascending=False) # Total number of null values
    percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False) # Percentage of values that are null
    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent']) # Putting the above two together
    return missing_data

missing_check(df_train)

isNull = df_train.isnull().sum().to_frame(name='isNull').T
isNa = df_train.isna().sum().to_frame(name='isNa').T
Unique = df_train.nunique().to_frame(name='Unique').T
pd.concat([Unique , isNa , isNull])

#df_cont=  ['ram','battery_power','clock_speed','fc','int_memory','m_dep','mobile_wt','n_cores','px_height','px_width','sc_h','sc_w','talk_time']
#df_categorical = ['blue','dual_sim','four_g','three_g','touch_screen','wifi','price_range']

df2 =df_train.copy()
df2.min()

#there are values equal to zero in both "px_height" and "sc_w". The problem with these points is that they cannot represent a feature of a mobile phone, as there is no 1D pixel or a 1D screen

px_H = df2['px_height'] == 0
sc_W = df2['sc_w'] == 0
print(f'pixel height = 0  :  {sum(px_H)}')
print(f'screen width = 0  :  {sum(sc_W)}')

px_mask = df2['px_height'] == 0
sc_mask = df2['sc_w'] == 0
print(f'pixel height = 0  :  {sum(px_mask)}')
print(f'screen width = 0  :  {sum(sc_mask)}')

df2=df2[df2['sc_w']>=2]
df2=df2[df2['px_height']>0]
df2.reset_index(inplace=True)
df2.drop('index', axis=1, inplace=True)
df2

# vidualtion categorical and numerical columns.
categorical_variables=[col for col in df2.columns if df2[col].nunique()<=8]
print('categorical:',categorical_variables)
continuous_variables=[col for col in df2.columns if df2[col].nunique()>8]
print('continuous:' ,continuous_variables)

#there are 8 categorical columns and 13 continuous columns

# check for cardinality in categorical variables
cate_cols=['blue', 'dual_sim','four_g','n_cores', 'three_g', 'touch_screen', 'wifi', 'price_range']
for var in cate_cols:

    print(var,':', ' contains ', len(df2[var].unique()), ' labels')

categorical = ['blue', 'dual_sim','four_g','n_cores', 'three_g', 'touch_screen', 'wifi', 'price_range']
sns.set_palette("tab10")
for i, col in enumerate(categorical):

    fig, axes = plt.subplots(1,2,figsize=(10,5))
# palette = 'hls'
    # count of col (countplot)
    sns.countplot(data=df_train, x=col, ax=axes[0] )
    for container in axes[0].containers:
        axes[0].bar_label(container)
    # count of col (pie chart)
    slices = df_train[col].value_counts().sort_index().values
    activities = [var for var in df_train[col].value_counts().sort_index().index]
    axes[1].pie(slices, labels=activities, shadow=True, autopct='%1.2f%%' ,startangle=90 )



    plt.suptitle(f'Count of Unique Value in {col} (Fig {i+1})',fontsize=15)
    plt.show()

plt.figure(figsize=(5,3))
categorical = ['blue', 'dual_sim','four_g','n_cores', 'three_g', 'touch_screen', 'wifi', 'price_range']
sns.set_palette("tab10")
for i, col in enumerate(categorical):

    fig= px.histogram(data_frame = df2, x = col, color = 'price_range',
                     title =f'Count of Unique Value in {col} (Fig {i+1})')

    fig.update_layout({'bargap': 0.5})
    fig.show()

#checking numerical data count
df3=df2.copy()
nume_cols=['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt',
           'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']

fig=plt.figure(figsize=(12,30))
for i,col in enumerate(nume_cols):
    ax=fig.add_subplot(7,2,i+1)
    sns.boxplot(y=df3[col],x=df3['price_range'], palette = "RdBu")

def dist_box(df3):
 # function plots a combined graph for univariate analysis of continous variable
 #to check spread, central tendency , dispersion and outliers
    Name=df3.name.upper()
    fig,(ax_box,ax_dis)  =plt.subplots(nrows=2,sharex=True,gridspec_kw = {"height_ratios": (.25, .75)},figsize=(8, 5))
    mean=df3.mean()
    median=df3.median()
    mode=df3.mode().tolist()[0]
    sns.set_theme(style="white")
    fig.suptitle("Distribution of OF DATA FOR "+ Name  , fontsize=18, fontweight='bold')
    sns.boxplot(x=df3,showmeans=True, orient='h',color="violet",ax=ax_box)
    ax_box.set(xlabel='')
     # just trying to make visualisation better. This will set background to white
    sns.despine(top=True,right=True,left=True) # to remove side line from graph


    ax_dis.axvline(mean, color='r', linestyle='--',linewidth=2)
    ax_dis.axvline(median, color='g', linestyle='-',linewidth=2)
    ax_dis.axvline(mode, color='y', linestyle='-',linewidth=2)
    plt.legend({'Mean':mean,'Median':median,'Mode':mode})
    sns.set_style('darkgrid')
    plt.grid()
    sns.histplot(df3,kde=True,color='blue',ax=ax_dis)
#select all quantitative columns for checking the spread
nume_cols=['battery_power', 'clock_speed', 'fc', 'int_memory', 'm_dep', 'mobile_wt',
           'pc', 'px_height', 'px_width', 'ram', 'sc_h', 'sc_w', 'talk_time']

for i in range(len(nume_cols)):
    dist_box(df3[nume_cols[i]])

#vis for numerical type
nume_cols = ['battery_power','fc','clock_speed','ram','talk_time','int_memory','m_dep',
       'mobile_wt','pc','px_height','px_width','sc_h','sc_w']
n_rows=5
n_cols=3
fig,ax = plt.subplots(n_rows, n_cols, figsize=(n_cols*3.5,n_rows*3.5))

for r in range (0,n_rows):
    for c in range(0,n_cols):
        idx = r*n_cols + c #index loop through list
        if idx <len(nume_cols):
            ax_idx = ax[r,c]
            sns.histplot(data=df3, x=nume_cols[idx],hue ='price_range',kde='true'
                         ,palette='RdYlGn_r',ax=ax_idx)
            ax_idx.set_title(f"Fig {idx+1}:Price_range vs {nume_cols[idx]}")
ax.flat[-1].set_visible(False) # remove subplot doesn't use
plt.tight_layout()
plt.show()

import plotly.graph_objs as go
df_pr_0 = df_train[df_train.price_range == 0]
df_pr_1 = df_train[df_train.price_range == 1]
df_pr_2 = df_train[df_train.price_range == 2]
df_pr_3 = df_train[df_train.price_range == 3]



trace1 =go.Scatter(
                    y = df_pr_0.battery_power,
                    x = df_pr_0.ram,
                    mode = "markers",
                    name = "Price Range: 0",
                    marker = dict(color = 'rgba(240, 136, 200, 0.8)'),
                    text= df_pr_0.price_range)


trace2 =go.Scatter(
                    y = df_pr_1.battery_power,
                    x = df_pr_1.ram,
                    mode = "markers",
                    name = "Price Range: 1",
                    marker = dict(color = 'rgba(255, 128, 2, 0.8)'),
                    text= df_pr_1.price_range)

trace3 =go.Scatter(
                    y = df_pr_2.battery_power,
                    x = df_pr_2.ram,
                    mode = "markers",
                    name = "Price Range: 2",
                    marker = dict(color = 'rgba(0, 240, 170, 0.8)'),
                    text= df_pr_2.price_range)

trace4 =go.Scatter(
                    y = df_pr_3.battery_power,
                    x = df_pr_3.ram,
                    mode = "markers",
                    name = "Price Range: 3",
                    marker = dict(color = 'rgba(50, 70, 190, 0.8)'),
                    text= df_pr_3.price_range)


data = [trace1, trace2, trace3, trace4]

layout = dict(title = 'Ram - Battery Power - Price Range',
              xaxis= dict(title= 'Ram',
                          ticklen= 5,zeroline= False),
              yaxis= dict(title= 'Battery Power',
                          ticklen= 5,zeroline= False),
             autosize=False,
             width=700,
             height=450,)
fig = dict(data = data, layout = layout)

iplot(fig)

# Modelling

#Decision tree

#defin x and y
x= df_train.drop(["price_range"],axis=1)
y=df_train["price_range"].values.reshape(-1,1)  #target

print('shape of x : {} \nshape of y : {}'.format(x.shape , y.shape))

# Returning the classification metrics for multi_class probelm.

def Report(y_test , y_pred):
    print('Accuracy : {}% \n'.format(accuracy_score(y_test , y_pred)*100))
    print('Confusion Matrix : \n\n{}\n'.format(confusion_matrix(y_test , y_pred)))
    print('Classification Report : \n\n{}'.format(classification_report(y_test , y_pred)))

def multi_class_metrics(y_true, y_pred):
    print(f'Accuracy  : ', round(metrics.accuracy_score(y_true, y_pred), 3))
    print(f'Precision : ', round(metrics.precision_score(y_true, y_pred, average = 'micro'), 3))
    print(f'Recall    : ', round(metrics.recall_score(y_true, y_pred, average = 'micro'), 3))
    print(f'f1        : ', round(metrics.f1_score(y_true, y_pred, average = 'micro'), 3))

# define a function to get x and y and  test size and mdepth to evaluate the model with different criterion and return the accuracy score

def get_score(x, y, test_size, mdepth, criterion):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)
    model = DecisionTreeClassifier(max_depth=mdepth, criterion=criterion)
    model.fit(x_train, y_train)
    y_pred = model.predict(x_test)
    score = accuracy_score(y_test, y_pred)
    return  score
# to draw a prettytable to show the accuracy score for different test size and max depth
from prettytable import PrettyTable

table = PrettyTable()
table.field_names = ["test_size", "max_depth", "criterion", "score"]

max_score = 0
max_value_mdepth = 0
max_value_test_size = 0
max_value_criterion = 0
for i in range(1, 5):
    for j in range(1, 20):
         for k in ['gini', 'entropy']:
            table.add_row([i/10, j, k, get_score(x, y, i/10, j, k)])
            if get_score(x, y, i/10, j, k) > max_score:
                max_score = get_score(x, y, i/10, j, k)
                test_size = i/10
                max_depth = j
                max_value_mdepth = max_depth
                max_value_test_size = test_size
                max_value_criterion = k

print(table)

print('max_score: ', max_score)
print('max_value_mdepth: ', max_value_mdepth)
print('max_value_test_size: ', max_value_test_size)
print('max_value_criterion: ', max_value_criterion)

# use the best test size and max depth to train the model
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=max_value_test_size, random_state=0)
model = DecisionTreeClassifier(max_depth=max_value_mdepth, random_state=0, criterion= max_value_criterion)
model.fit(x_train, y_train)

# predict the test data
y_pred = model.predict(x_test)

# get the accuracy score
score = accuracy_score(y_test, y_pred)
print('score: ', score)

Report(y_test , y_pred)

from yellowbrick.classifier import ConfusionMatrix

cm_DT = ConfusionMatrix(
    model, classes=[0,1,2,3])


cm_DT.fit(x_train, y_train)
cm_DT.score(x_test, y_test)

cm_DT.poof()
plt.show()

def Perform_cross_val(model, k, x, y, scoring):
    """
    perform cross validation
        model: model
        k(scaler): the value for n_splits in KFold()
        x(DataFrame or array):  x_train
        y(DataFrame or array): y_train
        scoring(string): an approach for evaluation in cross validation
    """

    kf = StratifiedKFold(n_splits=k)
    cv_results = cross_val_score(model, x, y.ravel(), cv=kf, scoring=scoring)
    cv_mean = np.mean(cv_results)

    print('-'*20, f"CV for k={k}, scoring={scoring}", '-'*20)
    print(f"CV mean: {cv_mean}")
    print(f"CV results: {cv_results}\n")

# Check cross validation on DTs model to estimate model performance (Accuracy)
# use MinMaxScaler
pipe1 = Pipeline([('scaler', MinMaxScaler()), ('DTs', DecisionTreeClassifier())])
Perform_cross_val(pipe1, k=5, x=x_train, y=y_train, scoring='accuracy')

# random forest

# define a function to get x and y and  test size and mdepth to evaluate the random forest model with different criterion and return the accuracy score

def get_score(x, y, test_size, mdepth, criterion):
    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=0)
    model2 = RandomForestClassifier(max_depth=mdepth, criterion=criterion)
    model2.fit(x_train, y_train)
    y_pred = model2.predict(x_test)
    score = accuracy_score(y_test, y_pred)
    return  score

# to draw a prettytable to show the accuracy score for different test size and max depth and criterion
from prettytable import PrettyTable

table = PrettyTable()

table.field_names = ["test_size", "max_depth", "criterion", "score"]

max_score = 0
max_value_mdepth = 0
max_value_test_size = 0
max_value_criterion = 0

for i in range(1, 5):
    for j in range(1, 20):
        for k in ['gini', 'entropy']:
            table.add_row([i/10, j, k, get_score(x, y, i/10, j, k)])
            if get_score(x, y, i/10, j, k) > max_score:
                max_score = get_score(x, y, i/10, j, k)
                test_size = i/10
                max_depth = j
                max_value_mdepth = max_depth
                max_value_test_size = test_size
                max_value_criterion = k

print(table)
print('max_score: ', max_score)
print('max_value_mdepth: ', max_value_mdepth)
print('max_value_test_size: ', max_value_test_size)
print('max_value_criterion: ', max_value_criterion)

# use the best test size and max depth to train the model
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=max_value_test_size, random_state=0)
RF = RandomForestClassifier(max_depth=max_value_mdepth, random_state=0, criterion= max_value_criterion)
RF.fit(x_train, y_train)


# predict the test data
y_pred = RF.predict(x_test)

# get the accuracy score
score = accuracy_score(y_test, y_pred)
print('score: ', score)

#Creating the Confusion matrix
cm = confusion_matrix(y_test, y_pred)
cm

cm_RF = ConfusionMatrix(
   RF, classes=[0,1,2,3])


cm_RF.fit(x_train, y_train)
cm_RF.score(x_test, y_test)

cm_RF.poof()
plt.show()

RF3 = RandomForestClassifier(max_depth =12,n_estimators=400, min_samples_split=3,
                            max_leaf_nodes=10,max_features='log2', max_samples=500, criterion='gini',random_state = 0)
RF3 = RF3.fit(x_train,y_train)
y_pred = RF3.predict(x_test)
Report(y_test , y_pred)

# SVM model

#split dataset in features and target variable
x = df_train.drop('price_range', axis=1)
y = df_train['price_range'].values.reshape(-1, 1) #Target variable

def SVM_Model(x, y, testSize):

    global x_train , x_test , y_train , y_test , y_pred

    rows = []

    for n in testSize:
        x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = n , random_state = 0)
        # Create SVM model
        svc=SVC(kernel='linear')
        svc.fit(x_train,y_train)

        y_pred=svc.predict(x_test)

        dataset = {'Test_size': n, 'accuracy':accuracy_score(y_test, y_pred), 'score': svc.score(x, y)}
        rows.append(dataset)
        evaluation3 = pd.DataFrame(rows)

    return (evaluation3)
# We want to hightlight the maximume values
def highlight_max(s):
    is_max = s == s.max()
    return ['background-color: green' if v else '' for v in is_max]
evaluation3 = SVM_Model(x, y, [0.1, 0.15, 0.2, 0.25, 0.3])
evaluation3.style.apply(highlight_max)
Report(y_test , y_pred)

from sklearn.svm import SVC

cm_SVM = ConfusionMatrix(
    svm , classes=[0,1,2,3])


cm_SVM.fit(x_train, y_train)
cm_SVM.score(x_test, y_test)

cm_SVM.poof()
plt.show()

model_performance = {
    "DecisionTree": {
        "Accuracy": 0.87
    },
    "RandomForest": {
        "Accuracy": 0.81
    },
    "SVM": {
        "Accuracy": 0.98
    }
}

# Get a list of model names from the dictionary
model_names = list(model_performance.keys())

# Find the best model based on accuracy
best_model = max(model_names, key=lambda x: model_performance[x]["Accuracy"])

print(f"Best Model: {best_model}")
print("Metrics:", model_performance[best_model])

# Hypertext parameter tuning
kernel=["linear","rbf"]
gamma=["auto",0.01,0.001,0.0001,1]
decision_function_shape=["ovo","ovr"]

svm=SVC(random_state=1)
grid_svm=GridSearchCV(estimator=svm,cv=5,
param_grid=dict(kernel=kernel,
                gamma=gamma,
                decision_function_shape=decision_function_shape))
grid_svm.fit(x_train,y_train)
print("best score: ", grid_svm.best_score_)
print("best param: ", grid_svm.best_params_)

# print how our model looks after hyper-parameter tuning
print(grid_svm.best_estimator_)

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Assuming your data is in X (features) and y (labels)

# Split data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Create an SVM classifier
svm_classifier = SVC(kernel='rbf')  # You can choose other kernels like 'linear', 'poly'

# Train the SVM classifier
svm_classifier.fit(x_train, y_train)

# Make predictions on the test set
y_pred = svm_classifier.predict(x_test)

# Evaluate model accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Testing

test_data = pd.read_csv("/content/test.csv")
df_test =pd.DataFrame(test_data)

# drop id column in data test
df_test = df_test.drop(['id'], axis=1)

df_test

#deleting noise like train data
df_test = df_test[df_test['px_height']>0]
df_test = df_test[df_test['sc_w']>=2]
df_test.reset_index( inplace = True)
df_test.drop('index',axis=1,inplace = True)
df_test

prediction_=svm_classifier.predict(df_test)
prediction_

df_test['price_range']=prediction_
df_test

import pickle

filename="svm_classifier.pkl"
with open (filename,'wb') as file:
    pickle.dump(svm_classifier,file)

with open (filename,'wb')as f:
    svm_classifier = pickle.load(f)

pred = svm_classifier.predict(np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]))
pred[0]


import pickle
import numpy as np

# Load the trained model
with open (filename,'wb') as file:
    pickle.dump(svm_classifier,file)

# Streamlit UI
st.title("Mobile Price Classification")
st.write("Enter the mobile features to predict the price category.")

# Input fields
battery_power = st.number_input("Battery Power", min_value=500, max_value=5000, value=2000)
ram = st.number_input("RAM (MB)", min_value=256, max_value=8000, value=2000)
internal_memory = st.number_input("Internal Memory (GB)", min_value=4, max_value=256, value=64)
num_cores = st.selectbox("Number of Cores", [1, 2, 4, 6, 8])

# Convert input into NumPy array
input_features = np.array([[battery_power, ram, internal_memory, num_cores]])

# Predict on button click
if st.button("Predict Price Category"):
    prediction = model.predict(input_features)
    st.success(f"Predicted Price Category: {prediction[0]}")

!streamlit run copy_of_mobile_classification_new.py
